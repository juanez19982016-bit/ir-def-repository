name: "Tier 4: Direct Sites"

on:
  workflow_dispatch:
  workflow_call:

jobs:
  download-direct:
    runs-on: ubuntu-latest
    timeout-minutes: 120

    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: pip install requests

      - name: Install rclone
        run: |
          curl -fsSL https://rclone.org/install.sh | sudo bash

      - name: Configure rclone
        env:
          RCLONE_TOKEN: ${{ secrets.RCLONE_DRIVE_TOKEN }}
        run: |
          mkdir -p ~/.config/rclone
          printf "[gdrive_repo]
type = drive
scope = drive
token = %s
team_drive =
" "$RCLONE_TOKEN" > ~/.config/rclone/rclone.conf

      - name: Download existing cache from Drive
        run: |
          rclone copy gdrive_repo:IR_DEF_REPOSITORY/.download_cache.json /tmp/ir_repository/ || true

      - name: Download Direct Sources
        run: |
          python scripts/download_and_organize.py \
            --tier direct \
            --output-dir /tmp/ir_repository

      - name: Show stats
        run: |
          echo "=== File counts ==="
          find /tmp/ir_repository -type f -not -name '.*' | wc -l
          echo "=== Disk usage ==="
          du -sh /tmp/ir_repository/ 2>/dev/null || true
          echo "=== Category breakdown ==="
          for d in /tmp/ir_repository/*/; do
            if [ -d "$d" ]; then
              echo "$(basename $d): $(find $d -type f | wc -l) files"
            fi
          done

      - name: Upload to Google Drive
        run: |
          rclone copy /tmp/ir_repository gdrive_repo:IR_DEF_REPOSITORY \
            --transfers 8 \
            --checkers 16 \
            --drive-chunk-size 64M \
            --fast-list \
            --stats 30s \
            --log-level INFO

      - name: Verify
        run: |
          rclone size gdrive_repo:IR_DEF_REPOSITORY || true
